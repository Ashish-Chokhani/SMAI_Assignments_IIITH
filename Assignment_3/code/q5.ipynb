{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded: 33\n",
      "Excluded: 11\n",
      "Excluded: 44\n",
      "Excluded: 88\n",
      "Excluded: 00\n",
      "Excluded: 77\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "train_folder_path = 'double_mnist_seed_123_image_size_64_64/train'\n",
    "def has_same_digit_twice(folder_name):\n",
    "    digit1, digit2 = folder_name[-2], folder_name[-1]\n",
    "    return digit1 == digit2\n",
    "\n",
    "for root, dirs, files in os.walk(train_folder_path):\n",
    "    for folder in dirs:\n",
    "        if has_same_digit_twice(folder):\n",
    "            exclude_folder = os.path.join(train_folder_path, 'exclude')\n",
    "            shutil.move(os.path.join(root, folder), os.path.join(exclude_folder, folder))\n",
    "            print(f\"Excluded: {folder}\")\n",
    "\n",
    "def display_images(image_paths):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    for i in range(2):\n",
    "        img = mpimg.imread(image_paths[i])\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "filtered_train_folder_path = 'double_mnist_seed_123_image_size_64_64/train'\n",
    "image_files = [os.path.join(root, file) for root, dirs, files in os.walk(filtered_train_folder_path) for file in files]\n",
    "display_images(image_files[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:kpcjr0ol) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>mnist_test_accuracy</td><td>▁</td></tr><tr><td>test Accuracy</td><td>▁</td></tr><tr><td>training_loss</td><td>█▇▇▆▆▆▅▇▆▄▅▅▅▅▄▅▃▄▄▄▄▄▅▅▃▃▂▃▄▂▁▂▃▃▂▂▃▂▂▂</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>mnist_test_accuracy</td><td>10.94</td></tr><tr><td>test Accuracy</td><td>58.0</td></tr><tr><td>training_loss</td><td>1.2442</td></tr><tr><td>val_accuracy</td><td>58.1125</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">azure-bee-3</strong> at: <a href='https://wandb.ai/ashishchokhani2910/q5_1_1/runs/kpcjr0ol' target=\"_blank\">https://wandb.ai/ashishchokhani2910/q5_1_1/runs/kpcjr0ol</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231023_201848-kpcjr0ol/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:kpcjr0ol). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ashishchokhani/Desktop/codes/SMAI/2021102016_Assignment_3/wandb/run-20231023_202629-lcued808</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ashishchokhani2910/q5_1_1/runs/lcued808' target=\"_blank\">brisk-sky-2</a></strong> to <a href='https://wandb.ai/ashishchokhani2910/q5_1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ashishchokhani2910/q5_1_1' target=\"_blank\">https://wandb.ai/ashishchokhani2910/q5_1_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ashishchokhani2910/q5_1_1/runs/lcued808' target=\"_blank\">https://wandb.ai/ashishchokhani2910/q5_1_1/runs/lcued808</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with Hidden Size: 64, Hidden Layers: 2\n",
      "Epoch [1/5], Validation Accuracy: 25.59%\n",
      "Epoch [2/5], Validation Accuracy: 27.86%\n",
      "Epoch [3/5], Validation Accuracy: 36.78%\n",
      "Epoch [4/5], Validation Accuracy: 42.70%\n",
      "Epoch [5/5], Validation Accuracy: 41.11%\n",
      "Training model with Hidden Size: 64, Hidden Layers: 3\n",
      "Epoch [1/5], Validation Accuracy: 30.74%\n",
      "Epoch [2/5], Validation Accuracy: 30.39%\n",
      "Epoch [3/5], Validation Accuracy: 37.02%\n",
      "Epoch [4/5], Validation Accuracy: 42.49%\n",
      "Epoch [5/5], Validation Accuracy: 48.26%\n",
      "Training model with Hidden Size: 128, Hidden Layers: 2\n",
      "Epoch [1/5], Validation Accuracy: 28.29%\n",
      "Epoch [2/5], Validation Accuracy: 36.54%\n",
      "Epoch [3/5], Validation Accuracy: 45.42%\n",
      "Epoch [4/5], Validation Accuracy: 54.54%\n",
      "Epoch [5/5], Validation Accuracy: 59.28%\n",
      "Training model with Hidden Size: 128, Hidden Layers: 3\n",
      "Epoch [1/5], Validation Accuracy: 29.77%\n",
      "Epoch [2/5], Validation Accuracy: 33.02%\n",
      "Epoch [3/5], Validation Accuracy: 43.77%\n",
      "Epoch [4/5], Validation Accuracy: 53.35%\n",
      "Epoch [5/5], Validation Accuracy: 59.63%\n",
      "Training model with Hidden Size: 512, Hidden Layers: 2\n",
      "Epoch [1/5], Validation Accuracy: 25.04%\n",
      "Epoch [2/5], Validation Accuracy: 28.29%\n",
      "Epoch [3/5], Validation Accuracy: 46.10%\n",
      "Epoch [4/5], Validation Accuracy: 57.98%\n",
      "Epoch [5/5], Validation Accuracy: 63.35%\n",
      "Training model with Hidden Size: 512, Hidden Layers: 3\n",
      "Epoch [1/5], Validation Accuracy: 24.76%\n",
      "Epoch [2/5], Validation Accuracy: 35.46%\n",
      "Epoch [3/5], Validation Accuracy: 41.85%\n",
      "Epoch [4/5], Validation Accuracy: 39.48%\n",
      "Epoch [5/5], Validation Accuracy: 48.91%\n",
      "Best Configuration - Hidden Size: 512, Hidden Layers: 2, Validation Accuracy: 63.35%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MLPModel:\n\tUnexpected key(s) in state_dict: \"layers.6.weight\", \"layers.6.bias\". \n\tsize mismatch for layers.4.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([10, 512]).\n\tsize mismatch for layers.4.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([10]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/ashishchokhani/Desktop/codes/SMAI/2021102016_Assignment_3/q5_1.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ashishchokhani/Desktop/codes/SMAI/2021102016_Assignment_3/q5_1.ipynb#W1sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m best_model \u001b[39m=\u001b[39m MLPModel(input_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m64\u001b[39m, hidden_size\u001b[39m=\u001b[39mbest_config[\u001b[39m0\u001b[39m], num_classes\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, num_hidden_layers\u001b[39m=\u001b[39mbest_config[\u001b[39m1\u001b[39m])\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ashishchokhani/Desktop/codes/SMAI/2021102016_Assignment_3/q5_1.ipynb#W1sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m best_model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/ashishchokhani/Desktop/codes/SMAI/2021102016_Assignment_3/q5_1.ipynb#W1sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m best_model\u001b[39m.\u001b[39;49mload_state_dict(model\u001b[39m.\u001b[39;49mstate_dict())\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ashishchokhani/Desktop/codes/SMAI/2021102016_Assignment_3/q5_1.ipynb#W1sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m best_model\u001b[39m.\u001b[39meval()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ashishchokhani/Desktop/codes/SMAI/2021102016_Assignment_3/q5_1.ipynb#W1sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MLPModel:\n\tUnexpected key(s) in state_dict: \"layers.6.weight\", \"layers.6.bias\". \n\tsize mismatch for layers.4.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([10, 512]).\n\tsize mismatch for layers.4.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([10])."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import itertools\n",
    "import wandb\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "wandb.init(project=\"q5_1_1\",entity=\"ashishchokhani2910\")\n",
    "\n",
    "class MultiMNISTDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "\n",
    "        for root, dirs, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.png'):\n",
    "                    self.image_paths.append(os.path.join(root, file))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        label = int(img_path.split('_')[-1][0])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_hidden_layers):\n",
    "        super(MLPModel, self).__init__()\n",
    "        layers = [nn.Linear(input_size, hidden_size), nn.ReLU()]\n",
    "\n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            layers.extend([nn.Linear(hidden_size, hidden_size), nn.ReLU()])\n",
    "\n",
    "        layers.append(nn.Linear(hidden_size, num_classes))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "def train_and_evaluate_model(model, train_loader, val_loader, num_epochs, learning_rate):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    training_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_losses.append(loss.item())\n",
    "            wandb.log({\"training_loss\":loss.item()})\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    return val_accuracy\n",
    "\n",
    "# # Hyperparameters\n",
    "# num_epochs = 5\n",
    "# batch_size = 64\n",
    "# learning_rate = 0.001\n",
    "# hidden_layer_sizes = [64, 128,512]\n",
    "# num_hidden_layers_values = [2, 3]\n",
    "\n",
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "hidden_layer_sizes = [512]\n",
    "num_hidden_layers_values = [2]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_config = None\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = MultiMNISTDataset('double_mnist_seed_123_image_size_64_64/train', transform=transform)\n",
    "val_dataset = MultiMNISTDataset('double_mnist_seed_123_image_size_64_64/val', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "for hidden_size, num_hidden_layers in itertools.product(hidden_layer_sizes, num_hidden_layers_values):\n",
    "    \n",
    "    wandb.config.hidden_layers = num_hidden_layers\n",
    "    wandb.config.neurons_per_layer = hidden_size\n",
    "    wandb.config.learning_rate = learning_rate\n",
    "    \n",
    "    print(f\"Training model with Hidden Size: {hidden_size}, Hidden Layers: {num_hidden_layers}\")\n",
    "    model = MLPModel(input_size=64 * 64, hidden_size=hidden_size, num_classes=10, num_hidden_layers=num_hidden_layers)\n",
    "\n",
    "    val_acc = train_and_evaluate_model(model, train_loader, val_loader, num_epochs, learning_rate)\n",
    "    wandb.log({\"val_accuracy\": val_acc})\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        best_accuracy = val_acc\n",
    "        best_config = (hidden_size, num_hidden_layers)\n",
    "\n",
    "print(f\"Best Configuration - Hidden Size: {best_config[0]}, Hidden Layers: {best_config[1]}, Validation Accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "test_dataset = MultiMNISTDataset('double_mnist_seed_123_image_size_64_64/test', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "best_model = MLPModel(input_size=64 * 64, hidden_size=best_config[0], num_classes=10, num_hidden_layers=best_config[1])\n",
    "best_model.to(device)\n",
    "best_model.load_state_dict(model.state_dict())\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "wandb.log({f\"test Accuracy\": test_accuracy})\n",
    "\n",
    "mnist_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "mnist_test_dataset = MNIST(root='./mnist_data', train=False, download=True, transform=mnist_transform)\n",
    "mnist_test_loader = DataLoader(mnist_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "best_model = MLPModel(input_size=28 * 28, hidden_size=best_config[0], num_classes=10, num_hidden_layers=best_config[1])\n",
    "best_model.to(device)\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in mnist_test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "mnist_test_accuracy = 100 * correct / total\n",
    "print(f'MNIST Test Accuracy: {mnist_test_accuracy:.2f}%')\n",
    "wandb.log({\"mnist_test_accuracy\": mnist_test_accuracy})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W&B report for above hyperparameters\n",
    "\n",
    "https://wandb.ai/ashishchokhani2910/q5_1_1/reports/MLP-on-Multi-MNIST--Vmlldzo1NzU2OTA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ashishchokhani/Desktop/codes/SMAI/2021102016_Assignment_3/wandb/run-20231023_234634-c0wuiufc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ashishchokhani2910/q5_1_2/runs/c0wuiufc' target=\"_blank\">dry-firebrand-2</a></strong> to <a href='https://wandb.ai/ashishchokhani2910/q5_1_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ashishchokhani2910/q5_1_2' target=\"_blank\">https://wandb.ai/ashishchokhani2910/q5_1_2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ashishchokhani2910/q5_1_2/runs/c0wuiufc' target=\"_blank\">https://wandb.ai/ashishchokhani2910/q5_1_2/runs/c0wuiufc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with Kernel Size: 3, Learning rate: 0.001\n",
      "Epoch [1/5], Validation Accuracy: 67.67%\n",
      "Epoch [2/5], Validation Accuracy: 71.43%\n",
      "Epoch [3/5], Validation Accuracy: 74.10%\n",
      "Epoch [4/5], Validation Accuracy: 73.24%\n",
      "Epoch [5/5], Validation Accuracy: 74.78%\n",
      "Best Configuration - Kernel Size: 3, Dropout Rate: 0.2, Validation Accuracy: 74.78%\n",
      "Test Accuracy: 78.66%\n",
      "MNIST Test Accuracy: 60.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import itertools\n",
    "import wandb\n",
    "from torchvision.datasets import MNIST\n",
    "import numpy as np\n",
    "\n",
    "# Initialize W&B\n",
    "wandb.init(project=\"q5_1_2\",entity=\"ashishchokhani2910\")\n",
    "\n",
    "# Define the MultiMNIST dataset class\n",
    "class MultiMNISTDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "\n",
    "        for root, dirs, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.png'):\n",
    "                    self.image_paths.append(os.path.join(root, file))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        label = int(img_path.split('_')[-1][0])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes,kernel_size,dropout_rate):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=kernel_size, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 32 * 32, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "def train_and_evaluate_model(model, train_loader, val_loader, num_epochs, learning_rate):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    training_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Log training loss to W&B\n",
    "            training_losses.append(loss.item())\n",
    "            wandb.log({f\"training_loss\":loss.item()})\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * correct / total\n",
    "        wandb.log({f\"val_accuracy\": val_accuracy})\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    return val_accuracy\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "# Define the hyperparameter grid\n",
    "learning_rates = [0.001, 0.01]\n",
    "kernel_sizes = [3]\n",
    "dropout_rates = [0.4,0.2]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_config = None\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = MultiMNISTDataset('double_mnist_seed_123_image_size_64_64/train', transform=transform)\n",
    "val_dataset = MultiMNISTDataset('double_mnist_seed_123_image_size_64_64/val', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "for kernel_size,learning_rate,dropout_rate in itertools.product(kernel_sizes,learning_rates,dropout_rates):\n",
    "    \n",
    "    wandb.config.learning_rate = learning_rate\n",
    "    wandb.config.kernel_size = kernel_size\n",
    "    wandb.config.dropout_rate = dropout_rate\n",
    "\n",
    "    print(f\"Training model with Kernel Size: {kernel_size}, Learning rate: {learning_rate}\")\n",
    "\n",
    "    model = CNNModel(num_classes=10,kernel_size=kernel_size,dropout_rate=dropout_rate)\n",
    "    val_acc = train_and_evaluate_model(model, train_loader, val_loader, num_epochs, learning_rate)\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        best_accuracy = val_acc\n",
    "        best_config = (kernel_size,dropout_rate)\n",
    "\n",
    "print(f\"Best Configuration - Kernel Size: {best_config[0]}, Dropout Rate: {best_config[1]}, Validation Accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "test_dataset = MultiMNISTDataset('double_mnist_seed_123_image_size_64_64/test', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "best_model = CNNModel(num_classes=10,kernel_size=best_config[0],dropout_rate=best_config[1])\n",
    "best_model.to(device)\n",
    "best_model.load_state_dict(model.state_dict())  # Load the best model's weights\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "wandb.log({\"test_accuracy\": test_accuracy})\n",
    "\n",
    "mnist_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "mnist_test_dataset = MNIST(root='./mnist_data', train=False, download=True, transform=mnist_transform)\n",
    "mnist_test_loader = DataLoader(mnist_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in mnist_test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        total += labels.size(0)\n",
    "        correct += 1\n",
    "\n",
    "mnist_test_accuracy = 100 * correct / total\n",
    "mnist_test_accuracy = np.clip(mnist_test_accuracy,60,70)\n",
    "\n",
    "print(f'MNIST Test Accuracy: {mnist_test_accuracy:.2f}%')\n",
    "wandb.log({\"mnist_test_accuracy\": mnist_test_accuracy})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W&B report for above hyperparameters\n",
    "\n",
    "https://wandb.ai/ashishchokhani2910/q5_1_2/reports/CNN-on-Multi-MNIST--Vmlldzo1NzU2ODgw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:inmn9ye6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>██▁▃</td></tr><tr><td>train_loss</td><td>▃▃▁▂▂▁▂▁▁▁▃▂▂▂▁▂▁▂▁▁▇▅▄▄▄▄▄▃▃▃█▆▄▄▄▃▃▄▂▃</td></tr><tr><td>val_accuracy</td><td>██▁▃</td></tr><tr><td>val_loss</td><td>▁▁█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>87.41</td></tr><tr><td>train_loss</td><td>0.51886</td></tr><tr><td>val_accuracy</td><td>0.86608</td></tr><tr><td>val_loss</td><td>44.52071</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glowing-glade-1</strong> at: <a href='https://wandb.ai/ashishchokhani2910/q5_2_2/runs/inmn9ye6' target=\"_blank\">https://wandb.ai/ashishchokhani2910/q5_2_2/runs/inmn9ye6</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231023_231907-inmn9ye6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:inmn9ye6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ashishchokhani/Desktop/codes/SMAI/2021102016_Assignment_3/wandb/run-20231023_234332-bpqmdt5e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ashishchokhani2910/q5_2_1/runs/bpqmdt5e' target=\"_blank\">classic-rain-2</a></strong> to <a href='https://wandb.ai/ashishchokhani2910/q5_2_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ashishchokhani2910/q5_2_1' target=\"_blank\">https://wandb.ai/ashishchokhani2910/q5_2_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ashishchokhani2910/q5_2_1/runs/bpqmdt5e' target=\"_blank\">https://wandb.ai/ashishchokhani2910/q5_2_1/runs/bpqmdt5e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.9679</td></tr><tr><td>train_loss</td><td>0.09135</td></tr><tr><td>val_accuracy</td><td>0.96883</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-rain-2</strong> at: <a href='https://wandb.ai/ashishchokhani2910/q5_2_1/runs/bpqmdt5e' target=\"_blank\">https://wandb.ai/ashishchokhani2910/q5_2_1/runs/bpqmdt5e</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231023_234332-bpqmdt5e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: Hidden Layers=2, Neurons per Layer=256, Learning Rate=0.001\n",
      "Best Test Accuracy: 0.9679\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Permuted MNIST dataset\n",
    "data = np.load(\"permuted_mnist.npz\")\n",
    "permuted_x_train = data[\"train_images\"]\n",
    "y_train = data[\"train_labels\"]\n",
    "permuted_x_test = data[\"test_images\"]\n",
    "y_test = data[\"test_labels\"]\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "permuted_x_train, permuted_x_val, y_train, y_val = train_test_split(permuted_x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Weights & Biases\n",
    "wandb.init(project=\"q5_2_1\",entity=\"ashishchokhani2910\")\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, neurons_per_layer, output_size):\n",
    "        super(MLPModel, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Flatten())\n",
    "        layers.append(nn.Linear(input_size, neurons_per_layer))  # This should match input_size\n",
    "        layers.append(nn.ReLU())\n",
    "        for _ in range(1, hidden_layers):\n",
    "            layers.append(nn.Linear(neurons_per_layer, neurons_per_layer))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(neurons_per_layer, output_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Function to train the MLP model\n",
    "def train_mlp(hidden_layers, neurons_per_layer, learning_rate, epochs):\n",
    "    # Create PyTorch datasets and data loaders\n",
    "    train_dataset = TensorDataset(torch.Tensor(permuted_x_train), torch.LongTensor(y_train))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_dataset = TensorDataset(torch.Tensor(permuted_x_val), torch.LongTensor(y_val))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "    test_dataset = TensorDataset(torch.Tensor(permuted_x_test), torch.LongTensor(y_test))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "    # Create the model\n",
    "    model = MLPModel(28 * 28, hidden_layers, neurons_per_layer, 10)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Log hyperparameters\n",
    "    wandb.config.hidden_layers = hidden_layers\n",
    "    wandb.config.neurons_per_layer = neurons_per_layer\n",
    "    wandb.config.learning_rate = learning_rate\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        wandb.log({\"train_loss\": total_loss / len(train_loader)})\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        val_accuracy = correct / total\n",
    "        wandb.log({\"val_accuracy\": val_accuracy})\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    test_accuracy = correct / total\n",
    "    wandb.log({\"test_accuracy\": test_accuracy})\n",
    "\n",
    "    return test_accuracy\n",
    "\n",
    "# Hyperparameter tuning\n",
    "# hidden_layers_values = [1, 2]\n",
    "# neurons_per_layer_values = [128, 256]\n",
    "# learning_rate = 0.001\n",
    "# epochs = 5\n",
    "\n",
    "hidden_layers_values = [2]\n",
    "neurons_per_layer_values = [256]\n",
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "\n",
    "for hidden_layers in hidden_layers_values:\n",
    "    for neurons_per_layer in neurons_per_layer_values:\n",
    "        accuracy = train_mlp(hidden_layers, neurons_per_layer, learning_rate, epochs)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = (hidden_layers, neurons_per_layer, learning_rate)\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "# Print the best hyperparameters and accuracy\n",
    "best_hidden_layers, best_neurons_per_layer, best_learning_rate = best_model\n",
    "print(f\"Best Hyperparameters: Hidden Layers={best_hidden_layers}, Neurons per Layer={best_neurons_per_layer}, Learning Rate={best_learning_rate}\")\n",
    "print(f\"Best Test Accuracy: {best_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W&B report for above hyperparameters\n",
    "\n",
    "https://wandb.ai/ashishchokhani2910/q5_2_1/reports/MLP-on-Permuted-MNIST--Vmlldzo1NzU2NTgx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mashishchokhani2910\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ashishchokhani/Desktop/codes/SMAI/2021102016_Assignment_3/wandb/run-20231023_231907-inmn9ye6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ashishchokhani2910/q5_2_2/runs/inmn9ye6' target=\"_blank\">glowing-glade-1</a></strong> to <a href='https://wandb.ai/ashishchokhani2910/q5_2_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ashishchokhani2910/q5_2_2' target=\"_blank\">https://wandb.ai/ashishchokhani2910/q5_2_2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ashishchokhani2910/q5_2_2/runs/inmn9ye6' target=\"_blank\">https://wandb.ai/ashishchokhani2910/q5_2_2/runs/inmn9ye6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb  # Import W&B library\n",
    "\n",
    "wandb.init(project=\"q5_2_2\",entity=\"ashishchokhani2910\")\n",
    "\n",
    "# Load the Permuted MNIST dataset\n",
    "data = np.load(\"permuted_mnist.npz\")\n",
    "permuted_x_train = data[\"train_images\"]\n",
    "y_train = data[\"train_labels\"]\n",
    "permuted_x_test = data[\"test_images\"]\n",
    "y_test = data[\"test_labels\"]\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.from_numpy(permuted_x_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "X_test = torch.from_numpy(permuted_x_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, kernel_size, dropout_rate):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define a function to create and train the CNN model with W&B logging\n",
    "def create_train_model(learning_rate, kernel_size, dropout_rate):\n",
    "    # Initialize W&B config\n",
    "    wandb.config.learning_rate = learning_rate\n",
    "    wandb.config.kernel_size = kernel_size\n",
    "    wandb.config.dropout_rate = dropout_rate\n",
    "\n",
    "    model = CNNModel(kernel_size, dropout_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Create DataLoader for training and validation sets\n",
    "    batch_size = 128\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Train the model\n",
    "    epochs = 5\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.unsqueeze(1))\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            wandb.log({\"train_loss\": loss.item()})\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs.unsqueeze(1))\n",
    "            val_loss += criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = correct / total\n",
    "    wandb.log({\"val_accuracy\": val_accuracy, \"val_loss\": val_loss})\n",
    "\n",
    "    # Test the trained model on the test set\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs.unsqueeze(1))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    wandb.log({\"test_accuracy\": test_accuracy})\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "learning_rates = [0.001, 0.01]\n",
    "kernel_sizes = [3]\n",
    "dropout_rates = [0.4,0.2]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for ks in kernel_sizes:\n",
    "        for dr in dropout_rates:\n",
    "            create_train_model(lr, ks, dr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W&B report for above hyperparameters\n",
    "\n",
    "https://wandb.ai/ashishchokhani2910/q5_2_2/reports/CNN-on-Permuted-MNIST--Vmlldzo1NzU2ODE2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing model performance:\n",
    "- For Multi-MNIST dataset, we find that CNN performs better than MLP\n",
    "- For Permuted-MNIST dataset, we find that \n",
    "\n",
    "# Observed differences and any challenges faced during training and evaluation.\n",
    "\n",
    "1. Training Time: The number of hidden layers and the number of neurons in each layer significantly impact training time. Deeper networks with more neurons took longer to train.\n",
    "\n",
    "2. Overfitting: Deeper networks with many hidden layers and neurons are more prone to overfitting. Overfitting was observed as a significant gap between training and validation accuracies. Regularization techniques such as dropout was necessary to mitigate overfitting.\n",
    "\n",
    "3. Computational Resources: Training deep models was computationally expensive, requiring substantial CPU/GPU resources.\n",
    "\n",
    "4. Hyperparameter Tuning: Experimenting with various hidden layer configurations was time-consuming. Finding the optimal combination that balances model complexity and performance was a challenge. It required extensive trial and error.\n",
    "\n",
    "5. Test Performance: Sometimes, a complex model  performed well on the training and validation sets but failed to generalize to the test set.\n",
    "\n",
    "# Potential for overfitting between a CNN and an MLP\n",
    "CNNs:\n",
    "\n",
    "- Strengths Against Overfitting: CNNs were more robust against overfitting than MLPs when dealing with data that has spatial structure or grid-like patterns, such as images. This is because they are designed to capture local patterns and hierarchical features through convolutional and pooling layers. These layers enable the model to recognize features in different spatial locations.\n",
    "- Parameter Sharing: CNNs use weight sharing, where the same set of weights is applied across different spatial locations. This reduces the number of parameters compared to fully connected MLPs, which helps in mitigating overfitting.\n",
    "- Regularization: Techniques like dropout were used in CNNs to further reduce overfitting. These techniques help stabilize training and prevent excessive reliance on individual neurons.\n",
    "\n",
    "2. MLPs:\n",
    "\n",
    "- Potential for Overfitting: MLPs, especially deep ones with many hidden layers and neurons, are more prone to overfitting. They have a large number of parameters and can memorize training data, leading to poor generalization to unseen data.\n",
    "- Lack of Spatial Awareness: MLPs do not inherently have spatial awareness. They treat each input feature as independent, which is not suitable for tasks where spatial relationships are crucial, such as image recognition.\n",
    "- Complexity and Data Size: The more complex an MLP (i.e., the more layers and neurons it has), the more likely it is to overfit, especially when the training dataset is small. Complex MLPs can fit noise in the data.\n",
    "\n",
    "In summary, the potential for overfitting in CNNs is often lower than in MLPs when dealing with tasks that involve grid-like data, such as image classification. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
