{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------2.2.1 Distribution of labels-------------------------\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import math\n",
    "import time\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# ------------------Loading the .npy file------------------------\n",
    "data = np.load('data.npy',allow_pickle=True)\n",
    "\n",
    "# ------------------Extracting the label column------------------\n",
    "label_column = data[:, 3]\n",
    "unique_labels, label_counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "#print(len(unique_labels)) There are total of 193 unique columns\n",
    "\n",
    "# --------------------Creating a bar chart------------------------\n",
    "plt.bar(unique_labels,label_counts)\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------2.3.1 KNN Class-------------------------\n",
    "class KNN:\n",
    "    #--------------------Initializing the class with parameters---------------\n",
    "    def __init__(self, encoder_type, k, distance_metric):\n",
    "        self.encoder_type = encoder_type\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "\n",
    "    #--------------------Modifying the parameters of class------------------\n",
    "    def modify_parameters(self, encoder_type, k, distance_metric):\n",
    "        self.set_encoder_type(encoder_type)\n",
    "        self.set_k(k)\n",
    "        self.set_distance_metric(distance_metric)\n",
    "\n",
    "    def set_encoder_type(self, encoder_type):\n",
    "        self.encoder_type = encoder_type\n",
    "\n",
    "    def set_k(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def set_distance_metric(self, distance_metric):\n",
    "        self.distance_metric = distance_metric\n",
    "    \n",
    "    def calculate_metric(self,X_val,y_val):\n",
    "        \n",
    "        y_val_pred=self.predict(X_val)\n",
    "        f1 = f1_score(y_val, y_val_pred, average='weighted',zero_division=0)\n",
    "        accuracy = accuracy_score(y_val, y_val_pred)\n",
    "        precision = precision_score(y_val, y_val_pred, average='weighted',zero_division=0)\n",
    "        recall = recall_score(y_val, y_val_pred, average='weighted',zero_division=0)\n",
    "\n",
    "        return f1,accuracy,precision,recall\n",
    "    \n",
    "    def split_data(self,data,test_ratio):\n",
    "\n",
    "        if self.encoder_type == 'ResNet':\n",
    "            encoded_data = data[:,1]\n",
    "        elif self.encoder_type == 'VIT':\n",
    "            encoded_data = data[:,2]\n",
    "        else:\n",
    "            encoded_data=None\n",
    "\n",
    "        label_data=data[:,3]\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(encoded_data,label_data,test_size=test_ratio)\n",
    "\n",
    "        return X_train,X_val,y_train,y_val\n",
    "    \n",
    "    def fit(self,X_train,y_train):\n",
    "        self.X_train=X_train\n",
    "        self.y_train=y_train\n",
    "    \n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for i in range(len(X_test)):\n",
    "            distances=np.array([])\n",
    "            #maintaining distances list for distance between every pair of training and testing set \n",
    "            for j in range(len(self.X_train)):\n",
    "                distance=self.calculate_distance(X_test[i],self.X_train[j])\n",
    "                distances=np.append(distances,distance)\n",
    "                \n",
    "            #returning indices of the first k neighbours\n",
    "            k_indices = heapq.nsmallest(self.k, range(len(distances)), key=lambda i: distances[i])\n",
    "\n",
    "            #extracting the labels of the k nearest neighbours training samples\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "\n",
    "            # Finding unique elements and their counts\n",
    "            unique_elements, counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "\n",
    "            # Finding the index of the element with the maximum count\n",
    "            max_frequency_index = np.argmax(counts)\n",
    "\n",
    "            # Getting the most common element\n",
    "            most_common_element = unique_elements[max_frequency_index]\n",
    "            predictions.append(most_common_element)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "    # ---------------------Computing the  distance---------------------------\n",
    "    def calculate_distance(self, data_point1, data_point2):\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            distance = self.euclidean_distance(data_point1, data_point2)\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            distance = self.manhattan_distance(data_point1, data_point2)\n",
    "        elif self.distance_metric == 'cosine':\n",
    "            distance = self.cosine_distance(data_point1, data_point2)\n",
    "        else:\n",
    "            distance = None \n",
    "        \n",
    "        return distance\n",
    "    \n",
    "    #--------------------Calculating euclidean distance--------------------\n",
    "    def euclidean_distance(self,x,y):\n",
    "        return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "    \n",
    "    #--------------------Calculating manhattan distance----------------------\n",
    "    def manhattan_distance(self,x,y):\n",
    "        return np.sum(np.abs(x - y))\n",
    "    \n",
    "    #--------------------Calculating cosine distance----------------------\n",
    "    def cosine_distance(self,x,y):\n",
    "        np_x = np.array(x)\n",
    "        np_y = np.array(y)\n",
    "        np_y=np_y.T\n",
    "        dot_product = np.dot(np_x,np_y)\n",
    "\n",
    "        norm_1 = np.linalg.norm(np_x)\n",
    "        norm_2 = np.linalg.norm(np_y)\n",
    "\n",
    "        cos_theta = dot_product / (norm_1 * norm_2)\n",
    "\n",
    "        return 1 - cos_theta\n",
    "\n",
    "    #-------------------Calcuating inference time for any triplet-------------------\n",
    "    def calculate_inference_time(self,encoder,k,distance_metric,test_ratio):\n",
    "\n",
    "        #------------------Fitting the hyperparameters-----------------------\n",
    "        self.modify_parameters(encoder,k,distance_metric)\n",
    "        X_train,X_val,y_train,y_val = self.split_data(data,test_ratio)\n",
    "        self.fit(X_train,y_train)\n",
    "\n",
    "        #-----------------------Initializing start time-----------------------\n",
    "        start_time = time.time()\n",
    "\n",
    "        f1,accuracy,precision,recall=self.calculate_metric(X_val,y_val)\n",
    "\n",
    "        #-----------------Taking difference between cur_time and start time--------------\n",
    "        inference_time = time.time() - start_time\n",
    "        \n",
    "        return inference_time,accuracy\n",
    "    \n",
    "    #-------------------Calcuating inference time for default triplet-------------------\n",
    "    def calculate_default_inference_time(self,encoder,k,distance_metric,test_ratio):\n",
    "\n",
    "        X_train,X_val,y_train,y_val = self.split_data(data,test_ratio)\n",
    "\n",
    "        knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "        X_train_flat = [item for sublist in X_train for item in sublist]\n",
    "        X_val_flat = [item for sublist in X_val for item in sublist]\n",
    "\n",
    "        #------------------Fitting the hyperparameters-----------------------\n",
    "        knn_classifier.fit(X_train_flat, y_train)\n",
    "\n",
    "        #-----------------------Initializing start time-----------------------\n",
    "        start_time = time.time()\n",
    "\n",
    "        #----------------Prdicting the label----------------------------\n",
    "        predictions = knn_classifier.predict(X_val_flat)\n",
    "\n",
    "        #-----------------Calculting the default accuracy------------------\n",
    "        accuracy_default = accuracy_score(y_val, predictions)\n",
    "\n",
    "        #-----------------Taking difference between cur_time and start time--------------\n",
    "        inference_time = time.time() - start_time\n",
    "        return inference_time,accuracy_default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------2.4.1 Best triplet-------------------------\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "distance_calculator = KNN(encoder_type='ResNet', k=29, distance_metric='cosine')\n",
    "\n",
    "test_ratio = 0.2\n",
    "\n",
    "N=(1-test_ratio)*len(data)\n",
    "max_len=int(math.sqrt(N))\n",
    "encoders = ['ResNet','VIT']\n",
    "distance_metrics = ['euclidean', 'manhattan', 'cosine']\n",
    "triplets_list=[]\n",
    "k_list=[]\n",
    "accuracy_list=[]\n",
    "\n",
    "for k in range(1,max_len+1,2):\n",
    "    for encoder in encoders:\n",
    "        for distance_metric in distance_metrics:\n",
    "\n",
    "            distance_calculator.modify_parameters(encoder,k,distance_metric)\n",
    "            X_train,X_val,y_train,y_val = distance_calculator.split_data(data,test_ratio)\n",
    "            distance_calculator.fit(X_train,y_train)\n",
    "\n",
    "            f1,accuracy,precision,recall=distance_calculator.calculate_metric(X_val,y_val)\n",
    "            \n",
    "            triplets_list.append(((k, encoder, distance_metric), accuracy))\n",
    "\n",
    "sorted_triplets = sorted(triplets_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#------------------------------Printing best triplet--------------------------\n",
    "print(f\"Best triplet: k={sorted_triplets[0][0][0]} Encoder={sorted_triplets[0][0][1]} Distance_metric={sorted_triplets[0][0][2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------2.4.2 20 Best triplets-------------------------\n",
    "\n",
    "# Selecting the top 20 triplets\n",
    "top_20_triplets = sorted_triplets[:20]\n",
    "\n",
    "table=PrettyTable()\n",
    "table.field_names = [\"Rank\",\"k\",\"Encoder\",\"Distance_Metric\",\"Accuracy\"]\n",
    "\n",
    "\n",
    "# Printing the top 20 triplets and their accuracies\n",
    "for rank, ((k, encoder, metric), accuracy) in enumerate(top_20_triplets, 1):\n",
    "    table.add_row([rank]+[k]+[encoder]+[metric]+[accuracy])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------2.4.3 Accuracy vs k plot-------------------------\n",
    "for k in range(1,max_len+1,2):\n",
    "\n",
    "    k_list.append(k)\n",
    "\n",
    "    distance_calculator.modify_parameters('VIT',k,'manhattan')\n",
    "    X_train,X_val,y_train,y_val = distance_calculator.split_data(data,test_ratio)\n",
    "    distance_calculator.fit(X_train,y_train)\n",
    "\n",
    "    f1,accuracy,precision,recall=distance_calculator.calculate_metric(X_val,y_val)\n",
    "    \n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "#--------------------------Plotting top 20 accuracies-------------------\n",
    "plt.plot(k_list,accuracy_list, marker='o', linestyle='-')\n",
    "plt.title('k vs. Accuracy Plot(Encoder=VIT distance_metric=manhattan)')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------2.6.2 Inference time plot-------------------------\n",
    "inference_time_initial,accuracy_initial=distance_calculator.calculate_inference_time('ResNet',29,'manhattan',test_ratio)\n",
    "inference_time_default,accuracy_default=distance_calculator.calculate_default_inference_time('ResNet',29,'manhattan',test_ratio)\n",
    "\n",
    "inference_time_optimized = float('inf')\n",
    "best_accuracy=float('-inf')\n",
    "\n",
    "for k in range(1,max_len+1,2):\n",
    "    for encoder in encoders:\n",
    "        for distance_metric in distance_metrics:\n",
    "            inference_time,accuracy_optimized=distance_calculator.calculate_inference_time(encoder,k,distance_metric,test_ratio)\n",
    "            inference_time_optimized=min(inference_time_optimized,inference_time)\n",
    "\n",
    "            if(accuracy_optimized>best_accuracy):\n",
    "                best_accuracy=accuracy_optimized\n",
    "                best_triplet=(encoder,k,distance_metric)\n",
    "\n",
    "\n",
    "inference_time_best,accuracy_best = distance_calculator.calculate_inference_time(best_triplet[0],best_triplet[1],best_triplet[2],test_ratio)\n",
    "\n",
    "print(f\"Initial inference time={inference_time_initial} Initial accuracy={accuracy_initial}\")\n",
    "print(f\"Best inference time={inference_time_best} Best accuracy={best_accuracy}\")\n",
    "print(f\"Optimized inference time={inference_time_optimized} Optimized accuracy={accuracy_optimized}\")\n",
    "print(f\"Default inference time={inference_time_default} Default accuracy={accuracy_default}\")\n",
    "\n",
    "models=['Initial KNN','Best KNN','Optimized KNN','Default KNN']\n",
    "Inference_time = [inference_time_initial,inference_time_best,inference_time_optimized,inference_time_default]\n",
    "\n",
    "table=PrettyTable()\n",
    "table.field_names = [\"Model\",\"Time\",\"Accuracy\"]\n",
    "table.add_row(['Initial']+[inference_time_initial]+[accuracy_initial])\n",
    "table.add_row(['Best']+[inference_time_best]+[best_accuracy])\n",
    "table.add_row(['Optimized']+[inference_time_optimized]+[accuracy_optimized])\n",
    "table.add_row(['Default']+[inference_time_initial]+[accuracy_default])\n",
    "\n",
    "print(table)\n",
    "\n",
    "plt.bar(models,Inference_time)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"inference time\")\n",
    "plt.title(\"Model vs Inference time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------2.6.2 Inference time vs train datasize-------------------------\n",
    "inference_time_initial_list=[]\n",
    "inference_time_best_list=[]\n",
    "inference_time_optimized_list=[]\n",
    "inference_time_default_list=[]\n",
    "train_ratio_list=[]\n",
    "\n",
    "for test_ratio in np.arange(0.1,0.6,0.1):\n",
    "\n",
    "    N=(1-test_ratio)*len(data)\n",
    "    max_len=int(math.sqrt(N))\n",
    "\n",
    "    inference_time_initial,accuracy_initial=distance_calculator.calculate_inference_time('ResNet',k,'manhattan',test_ratio)\n",
    "    inference_time_initial_list.append(inference_time_initial)\n",
    "\n",
    "    inference_time_default,accuracy_default=distance_calculator.calculate_default_inference_time('ResNet',k,'manhattan',test_ratio)\n",
    "    inference_time_default_list.append(inference_time_default)\n",
    "\n",
    "    inference_time_optimized = float('inf')\n",
    "    best_accuracy=float('-inf')\n",
    "\n",
    "    for k in range(1,max_len+1,2):\n",
    "        for encoder in encoders:\n",
    "            for distance_metric in distance_metrics:\n",
    "\n",
    "                inference_time,accuracy_optimized=distance_calculator.calculate_inference_time(encoder,k,distance_metric,test_ratio)\n",
    "                inference_time_optimized=min(inference_time_optimized,inference_time)\n",
    "\n",
    "                if(accuracy_optimized>best_accuracy):\n",
    "                    best_accuracy=accuracy_optimized\n",
    "                    best_triplet=(encoder,k,distance_metric)\n",
    "       \n",
    "    train_ratio_list.append(test_ratio)\n",
    "\n",
    "    inference_time_optimized_list.append(inference_time_optimized)\n",
    "\n",
    "    inference_time_best,accuracy_best = distance_calculator.calculate_inference_time(best_triplet[0],best_triplet[1],best_triplet[2],test_ratio)\n",
    "    inference_time_best_list.append(inference_time_best)\n",
    "\n",
    "\n",
    "for i in range(len(train_ratio_list)):\n",
    "    train_ratio_list[i] *= len(data)\n",
    "\n",
    "\n",
    "plt.plot(train_ratio_list, inference_time_initial_list, marker='o', label='Initial KNN')\n",
    "plt.plot(train_ratio_list, inference_time_best_list, marker='o', label='Best KNN')\n",
    "plt.plot(train_ratio_list, inference_time_optimized_list, marker='o', label='Optimized KNN')\n",
    "plt.plot(train_ratio_list, inference_time_default_list, marker='o', label='Default KNN')\n",
    "\n",
    "plt.title('Inference Time vs Training Dataset Size for KNN Models')\n",
    "plt.xlabel('Training Dataset Size')\n",
    "plt.ylabel('Inference Time (seconds)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------3.3.1 Decision Tree Class-------------------------\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import chain, combinations\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score,confusion_matrix,multilabel_confusion_matrix,hamming_loss\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "class MultiPowerDecisionTreeClassifier:\n",
    "\n",
    "    #--------------------Initializing the class with parameters---------------\n",
    "    def __init__(self, max_depth, max_features, criterion):\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.criterion = criterion\n",
    "        self.dt_model = DecisionTreeClassifier()\n",
    "    \n",
    "    #--------------------Modifying the parameters of class------------------\n",
    "    def modify_parameters(self,max_depth, max_features, criterion):\n",
    "        self.set_max_depth(max_depth)\n",
    "        self.set_max_features(max_features)\n",
    "        self.set_criterion(criterion)\n",
    "        \n",
    "    def set_max_depth(self,max_depth):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def set_max_features(self,max_features):\n",
    "        self.max_features = max_features\n",
    "\n",
    "    def set_criterion(self,criterion):\n",
    "        self.criterion = criterion\n",
    "    \n",
    "    def calculate_metric(self,X_test,y_test,formulation_type):    \n",
    "        y_val_pred=self.predict(X_test)\n",
    "\n",
    "        y_test = np.array(y_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_val_pred)\n",
    "        f1_micro = f1_score(y_test, y_val_pred, average='micro',zero_division=0)\n",
    "        f1_macro = f1_score(y_test, y_val_pred, average='macro',zero_division=0)\n",
    "        confusion = multilabel_confusion_matrix(y_test, y_val_pred)\n",
    "        cm=self.append_confusion_matrix(confusion,formulation_type,y_val_pred,y_test)\n",
    "        precision = precision_score(y_test, y_val_pred, average='weighted',zero_division=0)\n",
    "        recall = recall_score(y_test, y_val_pred, average='weighted',zero_division=0)\n",
    "        loss = hamming_loss(y_test, y_val_pred)\n",
    "\n",
    "        return accuracy,f1_micro,f1_macro,cm,precision,recall,1-loss\n",
    "    \n",
    "    def append_confusion_matrix(self,confusion_matric,formulation_type,y_pred,y_test):\n",
    "        if(formulation_type=='MultiOutput'):\n",
    "            result = np.sum(confusion_matric, axis=0)\n",
    "            return result\n",
    "        \n",
    "        confusion_matrices_per_label = {}\n",
    "        final_cm=[]\n",
    "\n",
    "        for label in range(8):\n",
    "            #8 is the length of unique labels\n",
    "            # Extract binary vectors for the current label\n",
    "            label_y_test = y_test[:, label]\n",
    "            label_y_pred = y_pred[:, label]\n",
    "            \n",
    "            # Calculate the confusion matrix for the current label\n",
    "            label_confusion_matrix = confusion_matrix(label_y_test, label_y_pred, labels=[0, 1])\n",
    "    \n",
    "            # Store the confusion matrix in the dictionary\n",
    "            confusion_matrices_per_label[label] = label_confusion_matrix\n",
    "            confusion_matrices_per_label[label] = np.array(confusion_matrices_per_label[label]) \n",
    "            # Convert the NumPy array to a nested list and store it in the dictionary\n",
    "            confusion_matrices_per_label[label] = label_confusion_matrix.tolist() \n",
    "            final_cm.append(confusion_matrices_per_label[label])\n",
    "\n",
    "        # Convert the list of matrices to a NumPy array\n",
    "        matrix_array = np.array(final_cm)\n",
    "\n",
    "        # Perform element-wise addition using NumPy\n",
    "        result = np.sum(matrix_array, axis=0)\n",
    "\n",
    "        return result\n",
    "\n",
    "    \n",
    "    def split_data(self,df,test_ratio,formulation_type):\n",
    "        X_encoded,binary_label_list = self.encode_data(df,formulation_type)\n",
    "        # Split the dataset into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_encoded,binary_label_list, test_size=test_ratio)\n",
    "        return X_train,X_test,y_train,y_test\n",
    "    \n",
    "    def encode_data(self,df,formulation_type):\n",
    "        # Perform one-hot encoding on categorical columns\n",
    "        X_encoded = pd.get_dummies(df.drop('labels', axis=1), columns=['gender','education','married','occupation','most bought item'])\n",
    "        y = df['labels']\n",
    "\n",
    "        #  Flat the list of strings into a single string\n",
    "        flat_string = ' '.join(y)\n",
    "        labels = flat_string.split()\n",
    "\n",
    "        # Get unique labels\n",
    "        unique_labels = set(labels)\n",
    "\n",
    "        binary_label_list=[]\n",
    "\n",
    "        if(formulation_type=='Powerset'):\n",
    "            # Generating power set\n",
    "            label_powerset = list(chain.from_iterable(combinations(unique_labels, r) for r in range(len(unique_labels) + 1)))\n",
    "\n",
    "            # Remove the empty subset\n",
    "            label_powerset = [subset for subset in label_powerset if len(subset) > 0]\n",
    "\n",
    "            filtered_label_powerset=[]\n",
    "\n",
    "            for tup in label_powerset:\n",
    "                result_string = ' '.join([' '.join(tup)])\n",
    "                filtered_label_powerset.append(result_string)\n",
    "\n",
    "            for i,tup in enumerate(filtered_label_powerset):\n",
    "                result_string = ' '.join(sorted(tup.split()))\n",
    "                filtered_label_powerset[i]=result_string\n",
    "\n",
    "\n",
    "            # Create a mapping dictionary to map label subsets to their corresponding indices\n",
    "            subset_to_index = {subset: i for i, subset in enumerate(filtered_label_powerset)}\n",
    "            index_to_subset = {i: subset for i, subset in enumerate(filtered_label_powerset)}\n",
    "\n",
    "\n",
    "            for label in y:\n",
    "                decimal_val=subset_to_index[' '.join(sorted(label.split()))]\n",
    "\n",
    "                # Convert the binary string to a list of binary digits (as integers)\n",
    "                binary_vector = np.zeros(2**len(unique_labels)-1,dtype=int)\n",
    "\n",
    "                binary_vector[decimal_val]=1\n",
    "\n",
    "                binary_label_list.append(binary_vector)\n",
    "\n",
    "        elif formulation_type=='MultiOutput':\n",
    "            # Create a mapping dictionary to map label to their corresponding indices\n",
    "            label_to_index = {label: i for i,label in enumerate(unique_labels)}\n",
    "            index_to_label = {i: label for i, label in enumerate(unique_labels)}\n",
    "\n",
    "            for label in y:\n",
    "                all_labels = label.split()\n",
    "                sorted_labels = sorted(all_labels)\n",
    "\n",
    "                # Create a binary vector\n",
    "                binary_vector = np.zeros(len(unique_labels),dtype=int)\n",
    "\n",
    "                for each_label in sorted_labels:\n",
    "                    binary_vector[label_to_index[each_label]]=1\n",
    "                \n",
    "                binary_label_list.append(binary_vector)\n",
    "        \n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        return X_encoded,binary_label_list\n",
    "\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        y_pred = self.dt_model.predict(X_test)\n",
    "        return y_pred\n",
    "    \n",
    "    def fit(self,X_train,y_train):\n",
    "        self.dt_model=DecisionTreeClassifier(max_depth=self.max_depth,max_features=self.max_features,criterion=self.criterion)\n",
    "        self.dt_model.fit(X_train,y_train)\n",
    "    \n",
    "    #----Used ChatGPT-------\n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'max_depth': self.max_depth,\n",
    "            'max_features': self.max_features,\n",
    "            'criterion': self.criterion,\n",
    "            # Include other hyperparameters as needed\n",
    "        }\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------3.4.1 Metric-------------------------\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('advertisement.csv')\n",
    "df = df.drop('city', axis=1)\n",
    "criterions = ['gini','entropy']\n",
    "max_depths = [3,5,10,20,30]\n",
    "max_features = [3,5,7,9,11]\n",
    "formulation_types=['Powerset','MultiOutput']\n",
    "powerset_metrics=[]\n",
    "multioutput_metrics=[]\n",
    "test_ratio=0.2\n",
    "\n",
    "DT = MultiPowerDecisionTreeClassifier(max_depth=30,max_features=11,criterion=\"gini\")\n",
    "\n",
    "for formulation_type in formulation_types:\n",
    "    for criterion in criterions:\n",
    "        for max_depth in max_depths:\n",
    "            for max_feature in max_features:\n",
    "                X_train,X_test,y_train,y_test = DT.split_data(df,test_ratio,formulation_type)\n",
    "                DT.fit(X_train,y_train)\n",
    "                val=DT.calculate_metric(X_test,y_test,formulation_type)\n",
    "                if formulation_type=='Powerset':\n",
    "                    powerset_metrics.append((formulation_type,criterion,max_depth,max_feature,) + val)\n",
    "                else:\n",
    "                    multioutput_metrics.append((formulation_type,criterion,max_depth,max_feature,) + val)\n",
    "\n",
    "# Create a PrettyTable instance with column names\n",
    "table_powerset = PrettyTable()\n",
    "table_powerset.field_names = ['Formulation_type','criterion','max_depth','max_features','Accuracy','F1_micro','F1_macro','Confusion_Matrix','Precision', 'Recall','Hamming']\n",
    "\n",
    "# Add rows of data \n",
    "for metrics_tuple in powerset_metrics:\n",
    "    table_powerset.add_row(list(metrics_tuple))\n",
    "\n",
    "print(table_powerset)     \n",
    "\n",
    "# Create a PrettyTable instance with column names\n",
    "table_MultiOutput = PrettyTable()\n",
    "table_MultiOutput.field_names = ['Formulation_type','criterion','max_depth','max_features','Accuracy','F1_micro','F1_macro','Confusion_Matrix','Precision', 'Recall','Hamming']\n",
    "\n",
    "# Add rows of data\n",
    "for metrics_tuple in multioutput_metrics:\n",
    "    table_MultiOutput.add_row(list(metrics_tuple))\n",
    "\n",
    "print(table_MultiOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------3.4.2 Top three oerforming set of hyperparameters-------------------------\n",
    "# Sort the results based on F1 micro score in descending order\n",
    "sorted_results = sorted(powerset_metrics, key=lambda x: x[5], reverse=True)\n",
    "\n",
    "# Take the top 3 combinations based on F1 micro score\n",
    "top_results_micro = sorted_results[:3]\n",
    "\n",
    "# Create a PrettyTable\n",
    "table_f1micro = PrettyTable()\n",
    "table_f1micro.field_names = [\"Formulation_Type\",\"criterion\",\"max_depth\",\"max_features\",\"F1 Micro Score\"]\n",
    "\n",
    "# Add data to the table\n",
    "for result in top_results_micro:\n",
    "    table_f1micro.add_row(['Powerset']+[result[1]]+[result[2]] +[result[3]] + [result[5]])\n",
    "\n",
    "print(table_f1micro)\n",
    "\n",
    "# Sort the results based on F1 macro score in descending order\n",
    "sorted_results = sorted(powerset_metrics, key=lambda x: x[6], reverse=True)\n",
    "\n",
    "# Take the top 3 combinations based on F1 macro score\n",
    "top_results_macro_powerset = sorted_results[:3]\n",
    "\n",
    "# Create a PrettyTable\n",
    "table_f1macro = PrettyTable()\n",
    "table_f1macro.field_names = [\"Formulation_Type\",\"criterion\",\"max_depth\",\"max_features\",\"F1 Macro Score\"]\n",
    "\n",
    "# Add data to the table\n",
    "for result in top_results_macro_powerset:\n",
    "    table_f1macro.add_row(['Powerset']+[result[1]]+[result[2]] +[result[3]] + [result[6]])\n",
    "\n",
    "print(table_f1macro)\n",
    "\n",
    "# Sort the results based on F1 micro score in descending order\n",
    "sorted_results = sorted(multioutput_metrics, key=lambda x: x[5], reverse=True)\n",
    "\n",
    "# Take the top 3 combinations based on F1 micro score\n",
    "top_results_micro = sorted_results[:3]\n",
    "\n",
    "# Create a PrettyTable\n",
    "table_f1micro = PrettyTable()\n",
    "table_f1micro.field_names = [\"Formulation_Type\",\"criterion\",\"max_depth\",\"max_features\",\"F1 Micro Score\"]\n",
    "\n",
    "# Add data to the table\n",
    "for result in top_results_micro:\n",
    "    table_f1micro.add_row(['MultiOutput']+[result[1]]+[result[2]] +[result[3]] + [result[5]])\n",
    "\n",
    "print(table_f1micro)\n",
    "\n",
    "# Take the top 3 combinations based on F1 macro score\n",
    "top_results_macro = sorted_results[:3]\n",
    "\n",
    "# Create a PrettyTable\n",
    "table_f1macro = PrettyTable()\n",
    "table_f1macro.field_names = [\"Formulation_Type\",\"criterion\",\"max_depth\",\"max_features\",\"F1 Macro Score\"]\n",
    "\n",
    "# Add data to the table\n",
    "for result in top_results_macro:\n",
    "    table_f1macro.add_row(['MultiOutput']+[result[1]]+[result[2]] +[result[3]] + [result[6]])\n",
    "\n",
    "print(table_f1macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------3.4.3 K-Fold-------------------------\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "#Implementing cross validation\n",
    "k =9\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "DT = MultiPowerDecisionTreeClassifier(top_results_macro_powerset[0][2],top_results_macro[0][3],top_results_macro[0][1])\n",
    "X,y = DT.encode_data(df,'MultiOutput')\n",
    "DT.fit(X,y)\n",
    "scores = cross_val_score(DT, X, y, cv=kf, scoring='accuracy')\n",
    "mean_accuracy = scores.mean()\n",
    "table_accuracy = PrettyTable()\n",
    "table_accuracy.field_names = [\"Type\",\"Model\",\"Accuracy\"]\n",
    "table_accuracy.add_row(['Default']+['MultiOutput']+[mean_accuracy])\n",
    "\n",
    "acc_score = []\n",
    "\n",
    "for train_index , test_index in kf.split(X):\n",
    "    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train , y_test = [y[i] for i in train_index] , [y[i] for i in test_index]\n",
    "    DT.fit(X_train,y_train)\n",
    "    pred_values = DT.predict(X_test)\n",
    "    acc = accuracy_score(pred_values , y_test)\n",
    "    acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/k\n",
    "table_accuracy.add_row(['Self']+['MultiOutput']+[avg_acc_score])\n",
    "\n",
    "DT = MultiPowerDecisionTreeClassifier(top_results_macro_powerset[0][2],top_results_macro[0][3],top_results_macro[0][1])\n",
    "X,y = DT.encode_data(df,'Powerset')\n",
    "DT.fit(X,y)\n",
    "scores = cross_val_score(DT, X, y, cv=kf, scoring='accuracy')\n",
    "mean_accuracy = scores.mean()\n",
    "table_accuracy.add_row(['Default']+['Powerset']+[mean_accuracy])\n",
    "\n",
    "acc_score = []\n",
    "\n",
    "for train_index , test_index in kf.split(X):\n",
    "    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train , y_test = [y[i] for i in train_index] , [y[i] for i in test_index]\n",
    "    DT.fit(X_train,y_train)\n",
    "    pred_values = DT.predict(X_test)\n",
    "     \n",
    "    acc = accuracy_score(pred_values , y_test)\n",
    "    acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/k\n",
    "table_accuracy.add_row(['Self']+['Powerset']+[avg_acc_score])\n",
    "\n",
    "print(table_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
